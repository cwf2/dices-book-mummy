{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9e6c06-7bd7-47c4-b5fa-08cdc4aa3e0f",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "## Import statements and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b796412a-7b00-4c27-9a8d-fee65b468285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"data\"\n",
    "spacy_file = \"spacy_tokens.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a023a591-70a6-49a4-8007-958b1bdf1219",
   "metadata": {},
   "source": [
    "## Collect speeches\n",
    "\n",
    "This executes all code in `1 - Collect Speeches.ipynb` and generates a DICES `SpeechGroup` called `test_speeches`, which we use below. To see in detail how the speeches are downloaded and pre-processed, you can run the first notebook separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28006dc-9f1e-42cf-a206-16e619de78d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"1 - Collect Speeches.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d35fb75",
   "metadata": {
    "id": "3d35fb75"
   },
   "source": [
    "# Run Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494bae25",
   "metadata": {
    "id": "494bae25"
   },
   "outputs": [],
   "source": [
    "# initialize spacy models\n",
    "spacy_load(\n",
    "    latin_model = 'la_core_web_lg',\n",
    "    greek_model = 'grc_odycy_joint_trf',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a0a5fa",
   "metadata": {
    "id": "65a0a5fa"
   },
   "outputs": [],
   "source": [
    "failed = []\n",
    "\n",
    "for i, s in enumerate(test_speeches):\n",
    "    if (i % 50 == 0) or (i == len(test_speeches) - 1):\n",
    "        print(f'\\r{round(i * 100 /len(test_speeches))} % complete', end='')\n",
    "    if s.passage.spacy_doc is None:\n",
    "        s.passage.runSpacyPipeline()\n",
    "    if s.passage.spacy_doc is None:\n",
    "        failed.append(s)\n",
    "\n",
    "if len(failed) > 0:\n",
    "    print(f'SpaCy failed for {len(failed)} speeches:')\n",
    "    for s in failed:\n",
    "        print(f' - {s.work.urn}\\t{s.work.title}\\t{s.l_range}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64024ab0",
   "metadata": {
    "id": "64024ab0"
   },
   "source": [
    "### Generate tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dbbcbb-ba27-48d1-8095-2f9af98cd320",
   "metadata": {
    "id": "75dbbcbb-ba27-48d1-8095-2f9af98cd320"
   },
   "outputs": [],
   "source": [
    "spacy_tokens = []\n",
    "\n",
    "# extract features\n",
    "for i, s in enumerate(test_speeches):\n",
    "    # progress\n",
    "    if (i % 200 == 0) or (i == len(test_speeches) - 1):\n",
    "        print(f'\\r{round(i * 100 /len(test_speeches))} % complete', end='')\n",
    "\n",
    "    # FIXME: getTextPos() breaks if Latin marks dieresis with e.g. Ã«\n",
    "    lastpos = 0\n",
    "    \n",
    "    # process all tokens in speech\n",
    "    for tok in s.passage.spacy_doc:\n",
    "\n",
    "        # FIXME: see above\n",
    "        textpos = s.passage.getTextPos(tok) or (lastpos + 1)\n",
    "        lastpos = textpos\n",
    "        \n",
    "        line_n = s.passage.line_array[s.passage.getLineIndex(tok)]['N'] if s.passage.getLineIndex(tok) is not None else None\n",
    "        spacy_tokens.append(dict(\n",
    "            speech_id = s.id,\n",
    "            lang = s.lang,\n",
    "            author = s.author.name,\n",
    "            work = s.work.title,\n",
    "            urn = s.work.urn,\n",
    "            l_fi = s.l_fi,\n",
    "            l_la = s.l_la,\n",
    "            nlines = len(s.passage.line_array),\n",
    "            spkr = ','.join([inst.name for inst in s.spkr]),\n",
    "            addr = ','.join([inst.name for inst in s.addr]),\n",
    "            part = s.part,\n",
    "            level = s.level,\n",
    "            line_n = line_n,\n",
    "            line_id = f'{s.work.urn}:{line_n}',\n",
    "            token = tok.text,\n",
    "            tok_id = f'{s.id}:{textpos}',\n",
    "            lemma = tok.lemma_,\n",
    "            pos = tok.pos_,\n",
    "            mood = tok.morph.get('Mood'),\n",
    "            tense = tok.morph.get('Tense'),\n",
    "            voice = tok.morph.get('Voice'),\n",
    "            person = tok.morph.get('Person'),\n",
    "            number = tok.morph.get('Number'),\n",
    "            case = tok.morph.get('Case'),\n",
    "            gender = tok.morph.get('Gender'),\n",
    "            verbform = tok.morph.get('VerbForm'),\n",
    "            degree = tok.morph.get('Degree'),\n",
    "            prontype = tok.morph.get('PronType'),\n",
    "        ))\n",
    "\n",
    "# convert to data frame\n",
    "spacy_tokens = pd.DataFrame(spacy_tokens)\n",
    "\n",
    "# simplify list cells\n",
    "cols = ['mood', 'tense', 'voice', 'person', 'number', 'case', 'gender', 'verbform', 'degree', 'prontype']\n",
    "spacy_tokens[cols] = spacy_tokens[cols].map(lambda x: None if len(x) == 0 else ','.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98834b1e-863c-4290-9341-b5969894da89",
   "metadata": {},
   "source": [
    "### Add Greek question marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3302cedc-b810-4f85-bd4e-f3e789c111dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_rows = []\n",
    "\n",
    "for s in test_speeches:\n",
    "    if s.lang == \"latin\":\n",
    "        continue\n",
    "    for match in re.finditer(\"(;)\", s.passage.text):\n",
    "        l_idx = 0\n",
    "        for next_l_idx, next_c_idx in enumerate(s.passage._line_index):\n",
    "            if next_c_idx > match.start():\n",
    "                break\n",
    "            else:\n",
    "                l_idx = next_l_idx\n",
    "        line_n = s.passage.line_array[l_idx][\"N\"]        \n",
    "        \n",
    "        extra_rows.append(dict(\n",
    "            speech_id = s.id,\n",
    "            lang = s.lang,\n",
    "            author = s.author.name,\n",
    "            work = s.work.title,\n",
    "            urn = s.work.urn,\n",
    "            l_fi = s.l_fi,\n",
    "            l_la = s.l_la,\n",
    "            nlines = len(s.passage.line_array),\n",
    "            spkr = ','.join([inst.name for inst in s.spkr]),\n",
    "            addr = ','.join([inst.name for inst in s.addr]),\n",
    "            part = s.part,\n",
    "            level = s.level,\n",
    "            line_n = line_n,\n",
    "            line_id = f'{s.work.urn}:{line_n}',\n",
    "            token = \";\",\n",
    "            tok_id = f'{s.id}:{match.start()}',\n",
    "            lemma = \";\",\n",
    "            pos = \"PUNCT\",\n",
    "        ))\n",
    "\n",
    "extra_rows = pd.DataFrame(extra_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ad06c-822a-40f6-93a8-71e0c2c13742",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tokens = (pd.concat([spacy_tokens, extra_rows], ignore_index=True)\n",
    "    .assign(temp=lambda df: df[\"tok_id\"].str.split(\":\"))\n",
    "    .assign(left=lambda df: df[\"temp\"].str[0].astype(int),\n",
    "            right=lambda df: df[\"temp\"].str[1].astype(int))\n",
    "    .sort_values(by=[\"left\", \"right\"])\n",
    "    .drop(columns=[\"left\", \"right\", \"temp\"])\n",
    "    .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792ea735-77cf-4be3-bd81-936bf8d3435a",
   "metadata": {},
   "source": [
    "### Save and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6796372-bcf4-403e-97f4-6cfbff54ea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to temp file\n",
    "spacy_tokens.to_csv(os.path.join(data_dir, spacy_file), index=False)\n",
    "\n",
    "# display\n",
    "display(spacy_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc8c3ba-504f-4904-8d26-a34620dba3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
