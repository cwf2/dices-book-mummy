{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "052e5793-fbcb-4067-9472-0bf97aa684b1",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "## File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d1547-1f3b-47c2-bef9-b234256cd1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "cltk_file = \"cltk_tokens.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08220ede",
   "metadata": {
    "id": "08220ede"
   },
   "source": [
    "# Collect speeches\n",
    "\n",
    "This executes all code in `1 - Collect Speeches.ipynb` and generates a DICES `SpeechGroup` called `test_speeches`, which we use below. To see in detail how the speeches are downloaded and pre-processed, you can run the first notebook separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x3hMdqpQuwo0",
   "metadata": {
    "id": "x3hMdqpQuwo0"
   },
   "outputs": [],
   "source": [
    "%run \"1 - Collect Speeches.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d35fb75",
   "metadata": {
    "id": "3d35fb75"
   },
   "source": [
    "# Run CLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6836a8e7-a8d2-4c40-91d0-4e18d70637aa",
   "metadata": {
    "id": "6836a8e7-a8d2-4c40-91d0-4e18d70637aa"
   },
   "outputs": [],
   "source": [
    "failed = []\n",
    "\n",
    "for i, s in enumerate(test_speeches):\n",
    "    if (i % 200 == 0) or (i == len(test_speeches) - 1):\n",
    "        print(f'\\r{round(i * 100 /len(test_speeches))} % complete', end='')\n",
    "\n",
    "    if s.passage.cltk_doc is None:\n",
    "        try:\n",
    "            s.passage.runCltkPipeline()\n",
    "        except:\n",
    "            if DEBUG:\n",
    "                print(s)\n",
    "                print(s.passage.text)\n",
    "            raise\n",
    "    if s.passage.cltk_doc is None:\n",
    "        failed.append(s)\n",
    "\n",
    "if len(failed) > 0:\n",
    "    print(f'CLTK failed for {len(failed)} speeches:')\n",
    "    for s in failed:\n",
    "        print(f' - {s.work.urn}\\t{s.work.title}\\t{s.l_range}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dced2b-be7b-439e-af44-4fb0443b595c",
   "metadata": {
    "id": "29dced2b-be7b-439e-af44-4fb0443b595c"
   },
   "outputs": [],
   "source": [
    "# Helper function to extract CLTK features as strings\n",
    "\n",
    "def getCltkFeature(token, feature, default=None):\n",
    "    '''convert token's feature bundle to a dictionary and perform a get'''\n",
    "    d = dict(zip([str(k) for k in token.features.keys()], token.features.values()))\n",
    "    vlist = d.get(feature)\n",
    "\n",
    "    if vlist is None:\n",
    "        return(default)\n",
    "\n",
    "    return [str(v) for v in vlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349af4fa-8d40-4301-b015-1c305dcb2d7c",
   "metadata": {
    "id": "62beb68d-37eb-4b6b-bd4c-bf3de454ab64"
   },
   "outputs": [],
   "source": [
    "cltk_tokens = []\n",
    "\n",
    "# extract features\n",
    "for i, s in enumerate(test_speeches):\n",
    "    # progress\n",
    "    if (i % 200 == 0) or (i == len(test_speeches) - 1):\n",
    "        print(f'\\r{round(i * 100 /len(test_speeches))} % complete', end='')\n",
    "\n",
    "    # process all tokens in speech\n",
    "    for tok in s.passage.cltk_doc:\n",
    "        if s.passage.getLineIndex(tok) is not None:\n",
    "            line_n = s.passage.line_array[s.passage.getLineIndex(tok)]['N']\n",
    "        else:\n",
    "            tok_idx = s.passage.getCltkWordIndex(tok)\n",
    "            if tok_idx == 0:\n",
    "                line_n = s.passage.line_array[0]['N']\n",
    "            elif tok_idx == len(s.passage.cltk_doc.words) - 1:\n",
    "                line_n = s.passage.line_array[-1]['N']\n",
    "            else:\n",
    "                left_tok = s.passage.cltk_doc[tok_idx-1]\n",
    "                left_line_idx = s.passage.getLineIndex(left_tok)\n",
    "                right_tok = s.passage.cltk_doc[tok_idx+1]\n",
    "                right_line_idx = s.passage.getLineIndex(right_tok)\n",
    "                if (left_line_idx is not None) and (right_line_idx is not None) and (left_line_idx == right_line_idx):\n",
    "                    line_n = s.passage.line_array[left_line_idx]['N']\n",
    "                else:\n",
    "                    line_n = None\n",
    "        cltk_tokens.append(dict(\n",
    "            speech_id = s.id,\n",
    "            lang = s.lang,\n",
    "            author = s.author.name,\n",
    "            work = s.work.title,\n",
    "            urn = s.work.urn,\n",
    "            l_fi = s.l_fi,\n",
    "            l_la = s.l_la,\n",
    "            nlines = len(s.passage.line_array),\n",
    "            spkr = ','.join([inst.name for inst in s.spkr]),\n",
    "            addr = ','.join([inst.name for inst in s.addr]),\n",
    "            part = s.part,\n",
    "            level = s.level,\n",
    "            line_n = line_n,\n",
    "            line_id = f'{s.work.urn}:{line_n}' if line_n is not None else None,\n",
    "            token = tok.string,\n",
    "            tok_id = f'{s.id}:{s.passage.getTextPos(tok)}',\n",
    "            lemma = tok.lemma,\n",
    "            pos = tok.upos,\n",
    "            mood = getCltkFeature(tok, 'Mood'),\n",
    "            tense = getCltkFeature(tok, 'Tense'),\n",
    "            voice = getCltkFeature(tok, 'Voice'),\n",
    "            aspect = getCltkFeature(tok, 'Aspect'),\n",
    "            person = getCltkFeature(tok, 'Person'),\n",
    "            number = getCltkFeature(tok, 'Number'),\n",
    "            case = getCltkFeature(tok, 'Case'),\n",
    "            gender = getCltkFeature(tok, 'Gender'),\n",
    "            degree = getCltkFeature(tok, 'Degree'),\n",
    "            verbform = getCltkFeature(tok, 'VerbForm'),\n",
    "        ))\n",
    "\n",
    "cltk_tokens = pd.DataFrame(cltk_tokens)\n",
    "\n",
    "# simplify list cells\n",
    "cols = ['mood', 'tense', 'voice', 'aspect', 'person', 'number', 'case', 'gender', 'degree', 'verbform']\n",
    "cltk_tokens[cols] = cltk_tokens[cols].map(lambda x: None if x is None else ','.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced65967-4d71-478b-b37f-6c0281afa656",
   "metadata": {},
   "source": [
    "### Fix NA line ids\n",
    "\n",
    "Consider dropping these lines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14410cb5-a024-4fea-96fc-64177ce851ae",
   "metadata": {
    "id": "14410cb5-a024-4fea-96fc-64177ce851ae"
   },
   "outputs": [],
   "source": [
    "mask = cltk_tokens['line_id'].isna()\n",
    "cltk_tokens.loc[mask, 'line_id'] = cltk_tokens.loc[mask, 'urn'] + ':' + cltk_tokens.loc[mask, 'token']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d090a2a3-149d-4dff-a2bf-31ba4d46f766",
   "metadata": {},
   "source": [
    "### Save and display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c739fefe-e133-49cb-ac01-f8be7dd4a604",
   "metadata": {
    "id": "62beb68d-37eb-4b6b-bd4c-bf3de454ab64"
   },
   "outputs": [],
   "source": [
    "# save to temporary file\n",
    "cltk_tokens.to_csv(os.path.join(data_dir, cltk_file), index=False)\n",
    "\n",
    "# display results\n",
    "display(cltk_tokens)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
