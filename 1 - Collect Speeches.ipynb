{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8db485e8-1c7e-4a7b-b544-6bae761dee61",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f116f-3d8b-4498-94d6-abf06f82d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import git\n",
    "import requests\n",
    "\n",
    "# DICES packages\n",
    "from dicesapi import DicesAPI, SpeechGroup\n",
    "from dicesapi.text import CtsAPI, spacy_load\n",
    "import dicesapi.text\n",
    "\n",
    "# for working with local CTS repositories\n",
    "from MyCapytain.resolvers.cts.local import CtsCapitainsLocalResolver\n",
    "from MyCapytain.resources.prototypes.metadata import UnknownCollection\n",
    "\n",
    "# for analysis\n",
    "import pandas as pd\n",
    "\n",
    "# verbose output\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeb275c-a368-4a93-b395-6d74f7985e3f",
   "metadata": {},
   "source": [
    "### Set up local text repositories\n",
    "\n",
    "Here we clone Christopher's fork of the Perseus Greek and Latin texts, so that we can use a local CTS resolver instead of querying the Perseus server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c130c2-b2ad-4b88-b797-bc6ad59795c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_names = ['canonical-greekLit', 'canonical-latinLit']\n",
    "\n",
    "print('Checking for local text repositories...')\n",
    "\n",
    "for repo in repo_names:\n",
    "    local_dir = os.path.join('data', repo)\n",
    "    remote_url = f'https://github.com/cwf2/{repo}.git'\n",
    "\n",
    "    if os.path.exists(local_dir):\n",
    "        print(f' - {local_dir} exists!')\n",
    "    else:\n",
    "        print(f' - retrieving {remote_url}')\n",
    "        git.Repo.clone_from(remote_url, local_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b83d06b-3c5b-4241-ab7e-c2ec60016653",
   "metadata": {},
   "source": [
    "### Connection to DICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd398589-3005-4bd4-b9f4-0f4bc70d449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = DicesAPI(\n",
    "    logfile = 'dices.log',\n",
    "    logdetail = 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994d5a9a-2f51-4654-88e8-b7d35850bfdd",
   "metadata": {},
   "source": [
    "### Set up local CTS connection\n",
    "\n",
    "This is the CTS API, allowing us to retrieve texts by URN. In this example, we not only instantiate a default CTS API, but we also create a local resolver that can serve texts from the local repositories we downloaded in the first cell.\n",
    "\n",
    "We have to do a little surgery to overwrite the default CTS API object's resolver with the local one.\n",
    "\n",
    "<div class=\"alert alert-warning\" style=\"margin:1em 2em\">\n",
    "    <p><strong>Note:</strong> The resolver will generate a lot of errors; these can be ignored unless they pertain to a text you want to retrieve.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b6d368-8b22-4013-96c0-fb43c2830ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to local repos\n",
    "repo_paths = [os.path.join('data', repo) for repo in repo_names]\n",
    "\n",
    "# create a local resolver\n",
    "local_resolver = CtsCapitainsLocalResolver(repo_paths, logger=api.log)\n",
    "\n",
    "# initialize the CTS API\n",
    "cts = CtsAPI(dices_api = api)\n",
    "\n",
    "# overwrite the default resolver\n",
    "cts._resolvers = {None: local_resolver}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ffdf06-2203-48ee-b0c9-7a6d70ec997a",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "### Download the entire DICES dataset\n",
    "\n",
    "We'll start by downloading records for all the speeches in DICES. Then we can select the mother speeches locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76853258-de1d-4879-aaca-ccc02465d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_speeches = api.getSpeeches()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed027a1-0535-4718-a6b4-18b7f2a9af9c",
   "metadata": {},
   "source": [
    "#### ⚠️ Workaround for certain Perseus texts\n",
    "\n",
    "These texts have an extra hierarchical level inserted into their loci on Perseus' CTS server. This is a temporary workaround to convert our loci to a form that the server understands.\n",
    "\n",
    "Because `all_speeches` and `mother_speeches` just contain pointers to the same object pool, we can do this modification once on `all_speeches` and the mother speeches will also be affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e761c-3930-41e7-a509-d3f79754397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_book_line = [\n",
    "    'De Raptu Proserpinae',\n",
    "    'In Rufinum',\n",
    "]\n",
    "adj_line = [\n",
    "    'Panegyricus de consulatu Manlii Theodori',\n",
    "    'Panegyricus de Tertio Consulatu Honorii Augusti',\n",
    "    'Panegyricus de Sexto Consulatu Honorii Augusti',\n",
    "    'Epithalamium de Nuptiis Honorii Augusti',\n",
    "    'De Bello Gothico',\n",
    "    'Psychomachia',\n",
    "]\n",
    "\n",
    "for s in all_speeches:\n",
    "    if s.work.title in adj_book_line:\n",
    "        m = re.fullmatch(r'(\\d+)\\.(\\d+)', s.l_fi)\n",
    "        if m:\n",
    "            s.l_fi = f'{m.group(1)}.1.{m.group(2)}'\n",
    "\n",
    "        m = re.fullmatch(r'(\\d+)\\.(\\d+)', s.l_la)\n",
    "        if m:\n",
    "            s.l_la = f'{m.group(1)}.1.{m.group(2)}'\n",
    "\n",
    "    elif s.work.title in adj_line:\n",
    "        m = re.fullmatch(r'(\\d+)', s.l_fi)\n",
    "        if m:\n",
    "            s.l_fi = '1.' + m.group(1)\n",
    "\n",
    "        m = re.fullmatch(r'(\\d+)', s.l_la)\n",
    "        if m:\n",
    "            s.l_la = '1.' + m.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec60900f-693e-42a5-b916-c85601346541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust loci for perseus editions\n",
    "\n",
    "errata_file = os.path.join('data', 'changed_loci.txt')\n",
    "errata = pd.read_csv(errata_file, sep='\\t', dtype=str)\n",
    "errata = dict([\n",
    "    (f'{row.author} {row.work} {row.l_fi_old}-{row.l_la_old}', (row.l_fi_new, row.l_la_new))\n",
    "    for row in errata.itertuples()])\n",
    "\n",
    "for s in all_speeches:\n",
    "    key = f'{s.author.name} {s.work.title} {s.l_range}'\n",
    "    if key in errata:\n",
    "        print(f'Corrected {s}', end=' ')\n",
    "        s.l_fi, s.l_la = errata[key]\n",
    "        print(f'to {s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8257f3-18a8-4ffb-9bc7-e6b64c67717f",
   "metadata": {},
   "source": [
    "### Get the text\n",
    "\n",
    "Because we're retrieving the texts from a local repository I've turned off caching to save memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7f5cab-eb05-43b2-adcb-996b36a80269",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = []\n",
    "\n",
    "for i, s in enumerate(all_speeches):\n",
    "    if (i % 200 == 0) or (i == len(all_speeches) - 1):\n",
    "        print(f'\\r{round(i * 100 /len(all_speeches))} % complete', end='')\n",
    "    if not hasattr(s, 'passage') or s.passage is None:\n",
    "        try:\n",
    "            s.passage = cts.getPassage(s, cache=False)\n",
    "        except:\n",
    "            s.passage = None\n",
    "    if s.passage is None:\n",
    "        failed.append(s)\n",
    "\n",
    "print()\n",
    "if DEBUG:\n",
    "    print (f'{len(failed)} failed:')\n",
    "    for s in failed:\n",
    "        print(f'\\t{s.author.name} {s.work.title} {s.l_range}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea517058-2919-4a27-9ff1-04484acdc098",
   "metadata": {},
   "source": [
    "### Add supplementary text for speeches not in Perseus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d967f9-449a-4516-8c97-e1c73ec63005",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('data', 'supp_mother_speeches.txt')\n",
    "\n",
    "with open(path) as f:\n",
    "    supplement = json.load(f)\n",
    "\n",
    "for rec in supplement:\n",
    "    for s in all_speeches:\n",
    "        if s.id == rec['id']:\n",
    "            s.passage = dicesapi.text.Passage()\n",
    "            s.passage.line_array = rec['line_array']\n",
    "            s.passage._line_index = []\n",
    "            cumsum = 0\n",
    "            for i in range(len(s.passage.line_array)):\n",
    "                s.passage._line_index.append(cumsum)\n",
    "                cumsum += len(s.passage.line_array[i]['text']) + 1\n",
    "            s.passage.text = ' '.join([l['text'] for l in s.passage.line_array])\n",
    "            s.passage.speech = s\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b6102a-1607-47b0-b477-e5c5176ebd90",
   "metadata": {},
   "source": [
    "### Remove speeches with no text available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12802cc2-e956-4c83-8f09-ac5303cb57c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_speeches = all_speeches.advancedFilter(lambda s: s.passage is not None).sorted()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba853a7-5271-4612-851a-c30232505afd",
   "metadata": {},
   "source": [
    "### Add book number to line array for multi-book speeches\n",
    "\n",
    "We have to add book identifiers to the line numbers in `line_array` for any speech spanning multiple books, in order to make sure that each line has a unique id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b54ab47-a0dd-4f96-b925-c22db0b8edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged = []\n",
    "for s in test_speeches:\n",
    "    if '.' not in s.l_fi:\n",
    "        for rec in s.passage.line_array:\n",
    "            rec['N'] = rec['n']\n",
    "    else:\n",
    "        pref_fi, n_fi = s.l_fi.rsplit('.', 1)\n",
    "        pref_la, n_la = s.l_la.rsplit('.', 1)\n",
    "\n",
    "        if pref_fi == pref_la:\n",
    "            n = int(n_fi) - 1\n",
    "\n",
    "            for rec in s.passage.line_array:\n",
    "                if rec['n'] is None:\n",
    "                    n = n + 1\n",
    "                    rec['N'] = pref_fi + '.' + str(n)\n",
    "                    if s not in flagged:\n",
    "                        flagged.append(s)\n",
    "                elif '.' not in rec['n']:\n",
    "                    rec['N'] = pref_fi + '.' + rec['n']\n",
    "                    n = int(rec['n'].replace('a', ''))\n",
    "                else:\n",
    "                    rec['N'] = rec['n']\n",
    "        else:\n",
    "            pref = int(pref_fi)\n",
    "            old_n = int(n_fi)\n",
    "\n",
    "            for rec in s.passage.line_array:\n",
    "                n = int(rec['n'])\n",
    "                if n < (old_n - 100):\n",
    "                    pref = pref + 1\n",
    "                rec['N'] = f'{pref}.{n}'\n",
    "                old_n = n\n",
    "\n",
    "if DEBUG:\n",
    "    for s in flagged:\n",
    "        print(s)\n",
    "        for rec in s.passage.line_array:\n",
    "            print(f'{rec[\"N\"]}\\t{rec[\"text\"]}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f641c3fa-51e8-45fb-ab27-402e26ed28bd",
   "metadata": {},
   "source": [
    "### Create fake URNs for any texts that don't have them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a9918-db21-4e3f-b421-8b3c230e1a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in test_speeches:\n",
    "    if s.work.urn is None or s.work.urn == '':\n",
    "        s.work.urn = f'{s.work.id}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
